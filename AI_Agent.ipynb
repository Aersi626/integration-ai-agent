{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6042598-10d5-4b0c-a2d3-8ec92b4fecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_string = \"\"\"yaml\n",
    "- route:\n",
    "    id: my-basic-route\n",
    "    from:\n",
    "      uri: direct:start\n",
    "    steps:\n",
    "      - log:\n",
    "          message: \"Processing message: ${body}\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb8a603-71dc-4ed3-87f0-282227abb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"You are an camel integration expert that make changes to the yaml file and return me the new yaml file\n",
    "\n",
    "Here is my original YAML files that I want you to make change:\n",
    "{yaml_string}\n",
    "\n",
    "Can you add a transformation step to this YAML file?\n",
    "\n",
    "After making the change, just repond me the new YAML file in yaml file format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3db867aa-da0a-47c9-b8d3-145b9b9f26ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sure! Here is the updated YAML file with the added transformation step:\n",
      "```yaml\n",
      "- route:\n",
      "    id: my-basic-route\n",
      "    from:\n",
      "      uri: direct:start\n",
      "    steps:\n",
      "      - log:\n",
      "          message: \"Processing message: ${body}\"\n",
      "      - transform:\n",
      "          type: xpath\n",
      "          expression: /Order/@id\n",
      "```\n",
      "In this updated YAML file, we have added a new step to the route named `transform`. This step uses an XPath expression to extract the value of the `@id` attribute from the `Order` element. The resulting value is then used as the input for the next step in the route, which in this case is the log step.\n",
      "\n",
      "Note that you may need to modify the XPath expression depending on the structure of your message data.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def query_ollama(prompt, model=\"codellama:7b\"):\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False,\n",
    "            \"temperature\": 0.2,\n",
    "            \"top_p\": 0.7,\n",
    "            \"num_predict\": 500,\n",
    "        }\n",
    "    )\n",
    "    return response.json()[\"response\"]\n",
    "\n",
    "#prompt = \"Generate a YAML file for a basic GitHub Actions workflow that runs tests on Python 3.10\"\n",
    "prompt = prompt.strip()\n",
    "print(query_ollama(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdea64f-3936-4b3f-8ecc-6000f52db009",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMChain\nretriever\n  Extra inputs are not permitted [type=extra_forbidden, input_value=VectorStoreRetriever(tags...C680>, search_kwargs={}), input_type=VectorStoreRetriever]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# Initialize the LLM chain with the Ollama model\u001b[39;00m\n\u001b[32m     48\u001b[39m llm = Ollama(model=\u001b[33m\"\u001b[39m\u001b[33mcodellama:7b\u001b[39m\u001b[33m\"\u001b[39m)  \n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m chain = \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     55\u001b[39m \u001b[43m)\u001b[49m \n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Run the chain with the YAML string and instructions\u001b[39;00m\n\u001b[32m     58\u001b[39m result = chain.invoke({\n\u001b[32m     59\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33myaml_string\u001b[39m\u001b[33m\"\u001b[39m: yaml_string,\n\u001b[32m     60\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minstructions\u001b[39m\u001b[33m\"\u001b[39m: instructions\n\u001b[32m     61\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aersi.aierzhati\\OneDrive - Cimetrix\\Desktop\\Cimetrix\\Sapience4.0\\cnvrg.io\\AI_agent\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:222\u001b[39m, in \u001b[36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    220\u001b[39m     warned = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    221\u001b[39m     emit_warning()\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aersi.aierzhati\\OneDrive - Cimetrix\\Desktop\\Cimetrix\\Sapience4.0\\cnvrg.io\\AI_agent\\venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001b[39m, in \u001b[36mSerializable.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: D419\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aersi.aierzhati\\OneDrive - Cimetrix\\Desktop\\Cimetrix\\Sapience4.0\\cnvrg.io\\AI_agent\\venv\\Lib\\site-packages\\pydantic\\main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for LLMChain\nretriever\n  Extra inputs are not permitted [type=extra_forbidden, input_value=VectorStoreRetriever(tags...C680>, search_kwargs={}), input_type=VectorStoreRetriever]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "# Load the YAML file as a document\n",
    "loader = TextLoader(\"./data/DSL_example.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the document into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Initialize the Ollama embeddings model\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# Create a FAISS vector store from the text chunks\n",
    "vector_store = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Define the YAML string and instructions\n",
    "instructions = '''add a transformation to this YAML file'''\n",
    "\n",
    "yaml_string = \"\"\"\n",
    "- route:\n",
    "    id: my-basic-route\n",
    "    from:\n",
    "      uri: direct:start\n",
    "    steps:\n",
    "      - log:\n",
    "          message: \"Processing message: ${body}\"\n",
    "\"\"\"\n",
    "\n",
    "# Define a prompt template for the LLM chain\n",
    "prompt_template = PromptTemplate.from_template('''\n",
    "you are an expert in YAML files and apache camel integration.\n",
    "Context:\n",
    "{context}\n",
    "Here is a YAML file that I want you to make change:\n",
    "{yaml_string}\n",
    "Can you make changes to this YAML file based on the following instructions?\n",
    "{instructions}\n",
    "After making the change, just respond with the new YAML file in YAML format.\n",
    "''')\n",
    "\n",
    "# Initialize the LLM chain with the Ollama model\n",
    "llm = Ollama(model=\"codellama:7b\")  \n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ") \n",
    "\n",
    "# Run the chain with the YAML string and instructions\n",
    "result = chain.invoke({\n",
    "    \"yaml_string\": yaml_string,\n",
    "    \"instructions\": instructions\n",
    "})\n",
    "\n",
    "# Print the result\n",
    "print(result['text'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52878516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6ztZcFP+kx60DZGtQioeTWPygk41szqhSvdeKPLorjo=\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "print(base64.b64encode(os.urandom(32)).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c014e629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64334057e270c32729e5d265aa9297fb5c48a95035d1f40ab11cee6345c72253\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import binascii\n",
    "print(binascii.hexlify(os.urandom(32)).decode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
